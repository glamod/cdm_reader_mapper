{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a data model for CLIWOC\n",
    "\n",
    "The purpose of this notebook is to demonstrate the structure of data models used by the `cdm_reader_mapper` toolbox.\n",
    "\n",
    "## ICOADS IMMA\n",
    "\n",
    "A common format for marine observational records is the ICOADS IMMA format. This is a text format, where each line contains the data (including metadata) for an individual record. The format is _attachment_ based, each record is constructed from a selection of (typically) fixed-width sections (called attachments) containing different subsets of the data or metadata associated with the record. Documentation on the format, and the available attachments can be found at [https://icoads.noaa.gov/e-doc/imma/R3.0-imma1.pdf](https://icoads.noaa.gov/e-doc/imma/R3.0-imma1.pdf).\n",
    "\n",
    "Records within the same file can contain different attachments, meaning that the IMMA format is not a fixed-width format, as line lengths will vary between records. Each record, however, must contain a certain subset of the attachments (in this case the `core` (or `c0`), `c1`, and `c98` attachments). \n",
    "\n",
    "### Supplementary Data\n",
    "\n",
    "Additional data or metadata can be provided in the `c99` attachment. This attachment is not fixed-width as different sources or decks can provide different collections of supplementary data.\n",
    "\n",
    "## CLIWOC\n",
    "\n",
    "In this example we use a subset of ICOADS release 3.0.0 IMMA formatted data for deck 730, which is data from the Climatological Database for the World's Oceans (CLIWOC). There is a large amount of supplementary data available in the `c99` attachment, which for deck 730 can be split into multiple sections. Here, we will start with the standard schema for the ICOADS IMMA format (included in `cdm_reader_mapper` as the `\"icoads\"` `imodel`), and extend the schema with fields for a subset of the `c99` attachment. We will add fields for the _logbook_ section of the `c99` attachment for this deck.\n",
    "\n",
    "An internal schema already exists for this deck (`\"icoads_r300_d730\"`), the purpose of this notebook is to demonstrate how one can extend the `\"icoads\"` data model to parse `c99` data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "* An initial read of the data subset using the `\"icoads\"` data model which does not parse the `c99` attachment.\n",
    "* Extension of the `\"icoads\"` schema to add fields for the logbook section of the `c99` attachment for deck 730.\n",
    "* Construction of a code table for a categorical field in the `c99` attachment.\n",
    "* Comparison with the internal schema for deck 730."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from cdm_reader_mapper import read_mdf, test_data\n",
    "from cdm_reader_mapper.mdf_reader.properties import _base as base\n",
    "\n",
    "try:\n",
    "    from importlib.resources import files as get_files\n",
    "except ImportError:\n",
    "    from importlib_resources import files as get_files\n",
    "\n",
    "from collections import OrderedDict\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "For this example we load a subset of ICOADS data for deck 730 from the `cdm_reader_mapper` test data. This is the data that will be used throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = test_data.test_icoads_r300_d730[\"source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Read\n",
    "\n",
    "First we read the data using the basic `\"icoads\"` data model. This isn't necessary for extending the schema, it is to highlight the raw `c99` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bundle = read_mdf(data_file_path, imodel=\"icoads\")\n",
    "data_raw = data_bundle.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary (`c99`) data\n",
    "\n",
    "By looking at the `c99` section we can see that the supplementary data has not been parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw[\"c99\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw[\"c99\"].iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Schema\n",
    "\n",
    "To use a custom schema we need to use the `ext_schema_path` argument in `read_mdf`. The structure of the directory is:\n",
    "\n",
    "```\n",
    "name_of_model/\n",
    "    name_of_model.json\n",
    "    code_tables/\n",
    "        ...\n",
    "```\n",
    "\n",
    "The `code_tables` sub-directory contains the code tables that map the key columns in the data to their values.\n",
    "\n",
    "In this example we create a temporary directory for the data model, so that it is cleaned up after the notebook is finished; in reality you would want to store the data model in a permanent directory!\n",
    "\n",
    "We start from the basic `\"icoads\"` model. The `c99` section will be based on the `\"icoads_r300_d730\"` schema and code tables.\n",
    "\n",
    "#### Copy the `\"icoads\"` schema\n",
    "\n",
    "First we create a copy of the `\"icoads\"` schema (located at `mdf_reader/schemas/icoads/icoads.json`). NOTE: `cdm_reader_mapper.mdf_reader.properties._base` is used so that we have a relative path to the original schema and code tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = TemporaryDirectory()\n",
    "my_model_name = \"cliwoc\"\n",
    "my_model_path = os.path.join(tmp_dir.name, my_model_name)\n",
    "os.mkdir(my_model_path)\n",
    "\n",
    "# Get a copy of the \"imma1\" schema\n",
    "icoads_schema_path = icoads_code_tables_path = get_files(\n",
    "    \".\".join([base, \"schemas\", \"icoads\"])\n",
    ")\n",
    "icoads_schema_path = os.path.join(icoads_schema_path, \"icoads.json\")\n",
    "\n",
    "my_schema_path = os.path.join(my_model_path, my_model_name + \".json\")\n",
    "copy = shutil.copyfile(icoads_schema_path, my_schema_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the code tables\n",
    "\n",
    "We now copy each of the `\"icoads\"` code tables. This includes generic `icoads` code tables (located in `mdf_reader/codes/icoads`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get code tables and copy to the directory\n",
    "my_code_tables_path = os.path.join(my_model_path, \"code_tables\")\n",
    "os.mkdir(my_code_tables_path)\n",
    "\n",
    "# Original code table directories (general ICOADS and Deck specific)\n",
    "icoads_code_tables_path = get_files(\".\".join([base, \"codes\", \"icoads\"]))\n",
    "\n",
    "# Get filenames for each of the code tables\n",
    "code_table_files = glob.glob(os.path.join(icoads_code_tables_path, \"ICOADS.*.json\"))\n",
    "\n",
    "# Copy each file\n",
    "for file in code_table_files:\n",
    "    basename = os.path.basename(file)\n",
    "    out_path = os.path.join(my_code_tables_path, basename)\n",
    "    shutil.copyfile(file, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extending the schema: CLIWOC logbook information\n",
    "\n",
    "For this example we'll load the schema into the environment as a dictionary (we use an ordered dictionary to guarantee that the ordering of the fields is maintained!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(my_schema_path) as io:\n",
    "    schema = json.load(io, object_pairs_hook=OrderedDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add the contents for section `c99`. There are some standard (\"header\"_ fields we need to supply. The `\"sentinel\"` is the prefix for the attachment, this is printed in the raw supplementary data and identifies the start of the attachment.\n",
    "\n",
    "We also need to specify the length of the attachment and the layout.\n",
    "\n",
    "We then add our data fields to the `elements` field for the `c99` section. We'll add the fields for the logbook component of the supplementary data for CLIWOC data, there are additional components we can resolve but we'll keep it to the logbook for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema[\"sections\"][\"c99\"][\"header\"][\"sentinel\"] = \"99 0 \"\n",
    "schema[\"sections\"][\"c99\"][\"header\"][\"disable_read\"] = False\n",
    "schema[\"sections\"][\"c99\"][\"header\"][\"field_layout\"] = \"fixed_width\"\n",
    "schema[\"sections\"][\"c99\"][\"header\"][\"length\"] = 245 + 5  # sentinel length\n",
    "schema[\"sections\"][\"c99\"][\"elements\"] = OrderedDict(\n",
    "    {\n",
    "        \"sentinel\": {\n",
    "            \"description\": \"attachment sentinel\",\n",
    "            \"field_length\": 5,\n",
    "            \"column_type\": \"str\",\n",
    "            \"ignore\": True,\n",
    "        },\n",
    "        \"InstAbbr\": {\n",
    "            \"description\": \"Abbreviation of the Institute storing the original data\",\n",
    "            \"field_length\": 8,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"InstName\": {\n",
    "            \"description\": \"Full name of the Institute storing the original data\",\n",
    "            \"field_length\": 50,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"InstCity\": {\n",
    "            \"description\": \"City where the Institute storing the data is located\",\n",
    "            \"field_length\": 10,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"InstCountry\": {\n",
    "            \"description\": \"Country where the Institute storing the data is located\",\n",
    "            \"field_length\": 14,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"ArchiveID\": {\n",
    "            \"description\": \"Administrative number under which the data is found within the Institute storing the data\",\n",
    "            \"field_length\": 15,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"ArchiveName\": {\n",
    "            \"description\": \"Administrative name under which the data is found within the Institute storing the data\",\n",
    "            \"field_length\": 17,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"ArchivePart\": {\n",
    "            \"description\": \"Part of the archive set in which the data is found within the Institute storing the data\",\n",
    "            \"field_length\": 39,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"ArchivePartSpec\": {\n",
    "            \"description\": \"Specification of the part of the archive set in which the data is found within the Institute storing the data\",\n",
    "            \"field_length\": 31,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"LogbookID\": {\n",
    "            \"description\": \"Identificaion Number of the logbook containing the data\",\n",
    "            \"field_length\": 30,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"LogbookLang\": {\n",
    "            \"description\": \"Language of the logbook containing the data\",\n",
    "            \"field_length\": 7,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"ImageID\": {\n",
    "            \"description\": \"Identificaion Number of the original image of the logbook\",\n",
    "            \"field_length\": 23,\n",
    "            \"column_type\": \"str\",\n",
    "        },\n",
    "        \"IllustrationAvail\": {\n",
    "            \"description\": \"Illustration available on the current page of the logbook\",\n",
    "            \"field_length\": 1,\n",
    "            \"column_type\": \"key\",\n",
    "            \"codetable\": \"CLIWOC_ILLUSTRATION_I\",\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write the dictionary to the schema file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(schema, indent=2)\n",
    "\n",
    "with open(my_schema_path, \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ImageAvail` Code Table\n",
    "\n",
    "One of the fields we have added has `\"column_type\"` of `\"key\"`. This is used to indicate categorical data, where the key value maps to a larger descriptive value. We also specified a code table for this field, which should describe that mapping. Let's create that table now. As with the schema it should be json formatted.\n",
    "\n",
    "For this field, we have two possible values. We save the dictionary to a json file in the code_tables directory, the name of the file must match the `\"codetable\"` value for the field (plus the `\".json\"` extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illustration_avail_codes = {\n",
    "    \"0\": \"No illustration on the current logbook page.\",\n",
    "    \"1\": \"Illustration available on the current logbook page.\",\n",
    "}\n",
    "illustration_avail_path = os.path.join(\n",
    "    my_code_tables_path, \"CLIWOC_ILLUSTRATION_I.json\"\n",
    ")\n",
    "\n",
    "json_object = json.dumps(illustration_avail_codes, indent=2)\n",
    "\n",
    "with open(illustration_avail_path, \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading\n",
    "\n",
    "We can now read the data file with the schema we have just created (copied...). We specify the path to the data model (the directory containing the schema json file) and the path to the code tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bundle = read_mdf(\n",
    "    data_file_path,  # Path to the data file\n",
    "    ext_schema_path=my_model_path,  # Path to the directory containing the schema json file\n",
    "    ext_table_path=my_code_tables_path,  # Path to the directory containing the json code tables\n",
    ")\n",
    "my_data = my_bundle.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing the output\n",
    "\n",
    "We can now investigate components of the c99 section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[[\"c99\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[[\"c99\"]].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Schema\n",
    "\n",
    "`cdm_reader_mapper` already includes a data model for the CLIWOC deck. The model parses all sections of supplementary data and provides all required code tables. Let's now read in the data using the `\"icoads_r300_d730\"` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = read_mdf(\n",
    "    data_file_path,\n",
    "    imodel=\"icoads_r300_d730\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `c99` section has been split into multiple sections. There is no `c99` section in the output, however we now have:\n",
    "\n",
    "* `c99_logbook`\n",
    "* `c99_voyage`\n",
    "* `c99_data`\n",
    "\n",
    "We can compare the `c99_logbook` section to the output of our model. We see that we have extracted the same data, although we chose different column names for the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.data[[\"c99_logbook\"]].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data[[\"c99\"]].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Sections\n",
    "\n",
    "We can also look at the additional components we did not parse in our model.\n",
    "\n",
    "We can note some remaining issues with the model as we look at the extra data. Most of the challenges relate to language translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "all_data.data[[\"c99_voyage\"]].describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.data[[\"c99_voyage\"]].c99_voyage.ZeroMeridian.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ship types and languages\n",
    "\n",
    "For example, the ship types on this deck will be given in many different languages. There is no code table for this variable in the CLIWOC website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.data[[\"c99_voyage\"]].c99_voyage.Ship_type.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.data[[\"c99_data\"]].c99_data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wind force scales and languages\n",
    "\n",
    "What about the different scales for the wind force, given different languages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.data[[\"c99_data\"]].c99_data.wind_force.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
